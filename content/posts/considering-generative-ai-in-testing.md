---
title: "关于生成式AI在测试行为中的思考"
date: 2024-08-07T09:23:52+08:00
draft: false
---

看到了一篇讨论测试和AI的文章，有些观点确实是非常正确的，顺手翻译了一下，供大家参考。

随着人们纷纷讨论生成式AI及其对行业的影响,我想概述一下它将如何影响测试,这是基于使用生成式AI所带来的风险。了解使用这些新工具带来的风险,将使我们能够获得相关信息,并思考在将其整合到团队中时所需的测试类型。

## 代码不如你自己写的那样

生成式AI通过抓取互联网内容来根据你给出的提示创建代码,这意味着你将继承其他开发者/代码编写者的风格和特点。那么会存在一个风险,即我们可能无法理解为我们编写的内容,使其对我们和团队来说更难维护和继承。还有一个风险是我们可能会简单地假设它在按照我们的要求执行,而不去验证(因为很难弄清楚代码在做什么)。

这可能会影响测试代码和产品代码的生成,我们可以通过对代码进行彻底的静态分析和重构来使其更易理解来应对这个问题。

## 不一致的编码习惯和风格

与上述情况类似,其他程序员的风格和习惯将被生成式AI抓取和使用。但这意味着每次你提示要求代码时,可能会得到不同的做事方式或编写代码的方式。我们可能会在可维护性和可继承性方面看到同样的问题,缺乏一致性使得发现问题变得更加困难。在代码所有权方面也可能存在问题,因为不清楚这是团队中谁的代码,所以我们不知道该问谁。代码集成方面也存在微小风险,不同的编码风格可能无法很好地协同工作,函数行为可能相互矛盾或冲突。

同样,需要进行更多的静态分析或代码重构,以及对函数行为进行基于代码的测试,以确保可理解性和正确性。

## 更大的维护开销

可能会更难让生成的代码与现有代码很好地配合,所以我们可能最终不得不替换代码而不是添加代码。这意味着我们可能会失去现有的代码测试,并增加代码行为不符合预期的风险。替换现有代码还意味着必须从头开始重新测试现有功能,特别是如果我们失去了接近代码的测试,这将增加测试所需的时间。

对代码(或代码中生成的测试)缺乏理解意味着每次我们想要添加到代码库时都需要花更多时间进行静态分析。应对这个问题的一种方法是为测试建立一个单独的代码库,这样对代码的更改就不会影响测试。测试人员还必须手动审查生成的测试,以确保它们对当前的代码库有意义。

## 工作表现如同实习生(很基础)

你的生成式AI创建的软件代码或自动化测试可能处于实习生的水平。你会得到你具体要求的内容,但不会考虑到细微之处或异常情况。这意味着存在覆盖不全的风险,也存在测试无法发现更深层次问题的风险。任何不确定性都可能导致做出与你的意图不符的假设,从而导致功能行为不佳。

应对这种情况的方法是确保仍然进行探索性测试和人工测试;测试人员不仅要审查已编写的测试,还要继续进行并覆盖生成式AI已经涉及的功能的准确性。我们还必须善于减少不确定性,并以不留任何假设空间的方式记录所有要求,以便输入到生成式AI中(不要相信它会有常识并知道失败应该导致错误)。

## 没有测试模型
由于你可能没有长篇大论地编写测试用例,而是使用提示,你不会有测试覆盖率的心理预期。我们也可能(如果过度依赖低代码或无代码测试工具)对代码/软件的行为没有很好的理解。这意味着软件的可维护性存在风险,以及可能会遗漏或错误测试边缘情况和功能的风险。

为了应对这些风险,我们需要制定计划来探索代码和功能,以了解它的工作原理。这种理解然后可以用于已生成的自动化测试,并支持知道要测试什么以及如何测试。

## 引入不良依赖项导致技术债务
生成式AI可能会抓取和引入过时的库,这存在风险,意味着你的代码可能不受支持或无法工作。尝试更新我们创建的代码可能会失败,或者如果生成式AI引入了我们不知道的会发生变化的库,就存在我们的代码有一天突然停止工作而我们不知道原因的风险。生成式AI使用的库可能会被污染,通过引入后门或恶意代码而带来安全漏洞,我们必须诊断和修复这些问题。

我们必须确保团队分析所使用的库,并在生成的代码中记录这些库,以便我们可以检查它们的有效性。还需要对所有生成的代码进行静态分析,以测试是否存在漏洞和安全缺陷(包括对生成式AI创建的任何功能进行渗透测试)。

## 未经训练的AI做出不直观的决策

所使用的AI可能会对创建什么代码、测试什么或如何测试做出糟糕的决定。如果代码不直观,我们可能无法从代码中逆向工程AI所做的假设。这给我们带来了无法理解或维护我们的代码和测试的风险,以及拥有对我们无用的测试或错过所需内容要点的风险。

除了对生成的代码进行静态分析和重构,使其更有意义并寻找糟糕的决策外,我们还需要开始为代码添加更详细和有意义的注释。AI需要被教导记录它创建的代码,我们做到这一点的方式是为它提供更好的例子,每个函数和每个测试都需要真正有意义的注释;这将训练AI做同样的事情,并让我们能够更好地诊断错误。

## 在招聘时偏向这种技能?

团队可能会开始过度重视招聘能够编写生成式AI提示的人,而不是测试或编码技能。我们可能最终会得到一支工程师团队,他们对软件开发的了解不足,无法诊断和纠正低代码开发带来的问题。这意味着我们无法修复的技术债务风险,或者团队不知道如何处理的主要底层架构问题。

测试人员需要挑战假设或支持消除团队的不确定性,以便创建生成式AI提示。测试人员还将在支持审查生成的代码的含义、可维护性和潜在工程缺陷方面发挥重要作用。这可能意味着高级工程师更有可能成为测试人员,因为他们可以支持处理生成代码的策略,或者可能意味着需要准备(并倡导)从头开始重建一切。

我们可能还需要帮助教育行业了解过度重视这种技能而牺牲工程和测试工艺所带来的风险。组织可能想要专注于雇用可以使用低代码解决方案的更便宜的工程师,而没有意识到其中固有的风险。

[来源](https://cakehurstryan.com/2024/07/26/considering-generative-ai-in-testing/)